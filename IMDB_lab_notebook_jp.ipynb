{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 映画またはテレビ番組が賞にノミネートされる、または受賞するかの予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2005 年、リードデータサイエンティストとして次のような課題に直面しています。Amazon Studios は映画賞を受賞するような作品を複数制作したいと考えています。受賞の可能性を最大限に引き出すために、予算をプロジェクトに集中しさせています。Amazon の子会社である IMDb の実際のデータセットを使用して、1990 年から 2005 年までに制作された映画について調査します。\n",
    "\n",
    "IMDb データセットは、この期間中に公開されたすべての映画に関する詳細で包括的なリストです。データセットには、映画の出演者、裏方、作品の概要、その他の制作データなど、重要なデータが含まれています。 このデータの多くはパブリックな IMDb.com サイトで公開され、公開されていないものはスタジオ分析のために非公開となっています。\n",
    "\n",
    "賞分析予測モデルを構築して、来るべき 2005年の賞シーズン中にノミネートされる可能性が最も高い映画を予測します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートブックにより、IMDB データベースからのデータのフィールドを読み取り、映画が賞に \"ノミネートされる\" または \"受賞する\" かを予測するためのモデルを構築します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このデータセットは IMDb の許可により提供されており、[AWS デジタルトレーニングサービス契約](https://aws.amazon.com/training/digital-training-agreement) の条項に従う必要があります。 このラボの実施以外の目的でデータセットをコピー、変更、販売、エクスポート、使用することは明示的に禁止されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   "## 必要なライブラリをインポートする\n",
    "\n",
    "ここでは、ライブラリを使ってモデルを事前処理し、予測を立てます\n",
    "（必要なほかのライブラリを追加することもできます）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libs into the python environment. These functions will be referenced later in the notebook code.\n",
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from IPython.display import Markdown, display\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D  # <-- Note the capitalization!\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set()\n",
    "\n",
    "\n",
    "# Modules from scikit-learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データについての考慮事項"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB データベースには大量の情報が含まれています。そのため、予測のどの種類のデータを用いるかが重要となります。使用するスキームは以下のようになります\n",
    "\n",
    "\n",
    "<img src=\"Data-Schema-Capstone.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データをクリーニングおよび可視化する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<LabBucketName\\>** をラボアカウントで提供されているリソース名と入れ変えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore \n",
    "bucket = '<LabBucketName>' # Update this to the bucket that was created in your lab account as part of this enviroment.\n",
    "prefix = 'data/'\n",
    " \n",
    "s3 = boto3.resource('s3') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw データファイルは AWS ラボアカウントの S3 バケットにあります。6 つのテーブルが使用されます（`title_genres`、`title_ratings`、`title_display`、`award_noms`、`title_awards`、`title_releases`）。Raw タブ区切り値ファイルが Amazon Sagemaker インスタンスにダウンロードされ、構造化データとの連動が簡単な DataFrame にインポートされます。Raw ファイルは行ヘッダーには含まれず、ラベルはインポート時に割り当てられています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_display_file(filename,names, title):\n",
    "    s3.Bucket(bucket).download_file(filename, filename)\n",
    "    user_info = pd.read_csv(filename, sep='\\t', encoding= 'latin1', names = names)\n",
    "    display(Markdown(\"**\" + title +\" Table** \\n\"))\n",
    "    display(user_info.head(5))\n",
    "    return user_info\n",
    "\n",
    "user_info_genres = download_and_display_file('title_genres.tsv', ['titleId','genres'], 'Genres')\n",
    "user_info_ratings = download_and_display_file('title_ratings.tsv', [\"titleId\",\"rating\",\"ratingCount\",\"topRank\",\"bottomRank\",\"topRankTV\"], 'Rating')\n",
    "user_info_display = download_and_display_file('title_display.tsv', [\"titleId\",\"title\",\"year\",\"adult\",\"runtimeMinutes\",\"imageUri\",\"imageId\",\"type\",\"originalTitle\"], 'Display')\n",
    "user_info_noms = download_and_display_file('award_noms.tsv', [\"awardId\",\"eventId\",\"event\",\"eventEditionId\",\"award\",\"category\",\"year\"], 'Nomination')\n",
    "user_info_awards = download_and_display_file('title_awards.tsv', [\"titleId\",\"awardId\",\"winner\"], 'Awards')\n",
    "user_info_releases = download_and_display_file('title_releases.tsv', [\"titleId\",\"ordering\",\"date\",\"region\",\"premiere\",\"wide\",\"premiereType\",\"festival\",\"attributes\"], 'Releases')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "テーブル形式 (.tsv) のデータはデータの事前処理のため Pandas DataFrame 内で使用されます。データは、6 つの異なるファイル間で、または DataFrames に分割されます。データをマージして、さらなるデータ探査、データエンジニアリング、可視化、およびモデル構築で使用される 統合された DataFrame 取得します。pandas の組み込み `merge` 関数を使って、DataFrames を一緒にマージします。`TitleId` は一意の ID で、このデータセットの各映画のタイトルに割り当てられています。`ttle_ratings`、`title_genres`、`title_display`、`title_releases` 間の一連の内部結合はすべてのテーブルを共にマージします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_merge = pd.merge(user_info_genres, user_info_ratings, on='titleId', how='inner')\n",
    "df_second_merge = pd.merge(df_first_merge, user_info_display, on='titleId', how='inner')\n",
    "df_third_merge = pd.merge(df_second_merge, user_info_releases, on='titleId', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(title_awards) テーブルとの外部結合を行う前に、重複した titleId が削除されます。DataFrame の結果として生じた重複は、いくつかのデータ列のとともに削除されます。IMDB データセットは数百ものフィールドが巨大なものです。ここでは、モデルの出力に影響を与える可能性がある関連するフィールドのみが選択されています。これらの関連するテーブルを読みこんだ後、次に示すように関連するフィールドのみが保持され、残りのフィールドは削除されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_third_merge = df_third_merge.drop_duplicates(['titleId'])\n",
    "df_fourth_merge = pd.merge(df_third_merge,user_info_awards,on='titleId', how='outer' )\n",
    "    \n",
    "df = df_fourth_merge.drop_duplicates(['titleId'])\n",
    "df = df.drop(['imageUri','topRank','bottomRank','topRankTV','ordering','premiereType','festival' ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果 DataFrame はシリアル化され、**Pickle** ライブラリを使用して Pickle と呼ばれるフラットファイルに書き込まれます。その後、このファイルはデータをあとで再使用するために Amazon S3 バケットに保存されます。`pickle.dump` を使って Pickle ファイルを作成し、raw データファイルをオブジェクトに保存して、ラボの S3 バケットにファイルをアップロードできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_pickle_nonoms_new.pkl', 'wb') as handle:\n",
    "    pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "s3.Bucket(bucket).upload_file('df_pickle_nonoms_new.pkl','data/df_pickle_nonoms_new.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最適化されたテーブルの上位 30 行を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新しい DataFrame でいくつかの基本的な pandas の記述統計を実行します。 \n",
    "\n",
    "`df.info()` は DataFrame に関する詳細情報を出力します。これには、インデックス dtype、列 dtypes、null 以外の値、メモリ使用量などの情報が含まれます。`df.describe()` は、平均値、中央値、最頻値などの記述統計を生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle ファイルを Pandas Dataframe に読み込み、無関係な作品の一部を削除します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.Bucket(bucket).download_file('data/df_pickle_nonoms_new.pkl', 'df_pickle_nonoms_new.pkl')\n",
    "df = pickle.load(open('df_pickle_nonoms_new.pkl', 'rb'))\n",
    "df = df[df.type == 'movie']\n",
    "df = df.drop(['imageId', 'originalTitle', 'awardId', 'attributes' ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果データは正規化が必要です。映画の上映時間がわからない場合は、ソースデータの値として `\\N` があります。データをプロットしようとする場合は、この null 値では問題が発生します。runtime の '\\N' を 0 に変更します。 \n",
    "\n",
    "同様に、映画のリリース年が不明な場合、値は '\\N' に設定されます。下のセルで、year の '\\N' を 0 に変更します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下に runtimeMinutes '\\N' のテーブルを示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.runtimeMinutes == r'\\N'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下に year `\\N` のテーブルを示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.year == r'\\N'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, mins in df['runtimeMinutes'].iteritems():\n",
    "    if mins == r'\\N':\n",
    "        better_name = '0'\n",
    "        df.loc[[i],['runtimeMinutes']] = better_name\n",
    "\n",
    "for i, year in df['year'].iteritems():\n",
    "    if year == r'\\N':\n",
    "        better_name = '0'\n",
    "        df.loc[[i],['year']] = better_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " DataFrame に `nomination_winner` という別の列が追加されます。winner の列が `0.0` または `1.0` の場合、その作品がノミネートされていると推測されます。それ以外の場合、作品はノミネートされていません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nomination_winner'] = 0\n",
    "for i, winner in df['winner'].iteritems():\n",
    "    if winner == (0.0):\n",
    "        better_name = 1\n",
    "        df.loc[[i],['nomination_winner']] = better_name\n",
    "    if winner == (1.0):\n",
    "        better_name = 1\n",
    "        df.loc[[i],['nomination_winner']] = better_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また `fillna` 関数を使用して、`year` 列と `runtimeMinutes` 列の欠損値を入力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.runtimeMinutes = df.runtimeMinutes.astype(float).fillna(0.0)\n",
    "df.year = df.year.astype(int).fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットに含まれる一部の作品には、上映時間が一致しないと思われるものがあります。runtime が 1 時間（60 分）より長く、12 時間（720 分）以下のデータに制限します。また `reviewCount` が 20,000 未満の作品にも注力します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下に `runtimesMinutes` が 60 分未満のサンプルデータを示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.runtimeMinutes) < 60].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下に `runtimesMinutes` が 720 分未満のサンプルデータを示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.runtimeMinutes) > 720].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.runtimeMinutes) > 60]\n",
    "df = df[(df.runtimeMinutes) < 720]\n",
    "df = df[(df.ratingCount) < 20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**最適化されたデータの上位 30 列を確認します。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*50)\n",
    "df.info()\n",
    "print('='*50)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**以下で、将来使用するために 2005 年のデータフレームを df_2005 として保存しています。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2005 = df[(df.year) == 2005]\n",
    "df_2005.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量選択と特徴量エンジニアリング\n",
    "<a id='feature selection'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**特徴量選択ボックス:** さまざまな特徴量と選択の切り替えスイッチは以下の通りです。値 0 は特徴量を無効化し、1 は有効化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection of different features\n",
    "\n",
    "feature_winner = 0          # Select this feature to make prediction on award winner. \n",
    "                            # Disable this feautre to make prediction on nomination winners.\n",
    "    \n",
    "feature_pca_2D = 0          # Select this feature to perform Principal Component Analysis of 2 components.\n",
    "feature_pca_3D = 1          # Select this feature to perform Principal Component Analysis of 3 components.\n",
    "\n",
    "feature_premiere = 0        # Select this feature to limit analysis on limited premiered movies.\n",
    "feature_wide = 0            # Select this feature to limit analysis on world wide premiered movies.\n",
    "feature_premiere_wide = 1   # Select this feature to include analysis on both limited and wide premiered movies.\n",
    "\n",
    "\n",
    "# Normalize features\n",
    "normalize_flag = 0\n",
    "\n",
    "#Enable plotting\n",
    "plot_flag = 1                 \n",
    "\n",
    "#Feaure Selection \n",
    "US_flag = 1                 # Select this feature to limit analysis on US based movies.\n",
    "\n",
    "#Model Selection flags\n",
    "LR_flag = 1\n",
    "DT_flag = 1\n",
    "RF_flag = 1\n",
    "GB_flag = 1\n",
    "NN_flag = 1\n",
    "SVM_flag = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**データのクリーンアップと制約:** \n",
    "- データを **US** 特徴のに見制限して探索します。\n",
    "- 出力ターゲットとして **ノミネート** を使用するか、**受賞**  を使用するかを選択して探索します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_flag: \n",
    "    prob = df.region.value_counts(normalize=True)\n",
    "    threshold = 0.02\n",
    "    mask = prob > threshold\n",
    "    tail_prob = prob.loc[~mask].sum()\n",
    "    prob = prob.loc[mask]\n",
    "    prob['other'] = tail_prob\n",
    "    prob.plot(kind='bar')\n",
    "    plt.xticks(rotation=25)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "if US_flag:\n",
    "    df = df[ (df.region) == 'US']\n",
    "\n",
    "\n",
    "# This flag is set if \"winner\" is chosen as output label\n",
    "\n",
    "if feature_winner:\n",
    "    df = df[(df.nomination_winner) == 1]\n",
    "\n",
    "    for i, winner in df['winner'].iteritems():\n",
    "        if winner == (0.0):\n",
    "            better_name = 0\n",
    "            df.loc[[i],['nomination_winner']] = better_name\n",
    "        if winner == (1.0):\n",
    "            better_name = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この特徴をグラフ化して、特徴が相互にどのように関連しているかわかりやすくします。以下は、データがインポートされた後に呼び出される関数を定義しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot Confusion Matrix function\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# end Confusion Matrix function\n",
    "\n",
    "\n",
    "# ROC Curve Plotting function\n",
    "\n",
    "def plot_roc_curve(fpr,tpr):\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b',\n",
    "             label='AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlim([-0.1, 1.2])\n",
    "    plt.ylim([-0.1, 1.2])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "#end ROC plotting function\n",
    "\n",
    "\n",
    "# Precision Recall (PR) function\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "    plt.xlabel(\"Threshold\", fontsize=16)\n",
    "    plt.legend(loc=\"upper left\", fontsize=16)\n",
    "    plt.ylim([0, 1])\n",
    "    plt.show( )\n",
    "    plt.close()\n",
    "\n",
    "#end PR function\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下では、`rating`、`ratingCount` などの異なる特徴のヒストグラムをプロットします。出力の `premier` フラグの効果を確認します。また出力だけでなく、さまざまな特徴間の影響や相互関係も調べます。`ratingCount` は、出力 `nomination_winner` (`nomination` または `winner`) に最大の影響することがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot rating vs rating count & Histogram of Rating\n",
    "\n",
    "if plot_flag:\n",
    "    \n",
    "    df['rating'].hist()\n",
    "    plt.title('Histogram of Ratings')\n",
    "    plt.xlabel('Rating')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    df_plot = df[(df.ratingCount) < 10000]\n",
    "    df_plot['ratingCount'].hist(bins=100)\n",
    "    plt.title('Histogram of Rating Count')\n",
    "    plt.xlabel('Rating Count')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plot_hist1 = df[(df.nomination_winner) == 1]\n",
    "    plot_hist0 = df[(df.nomination_winner) == 0]\n",
    "    plt.hist(df.nomination_winner)\n",
    "    plt.hist(plot_hist1.premiere)\n",
    "    plt.xlabel('Nomination/Premiere')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    " \n",
    "    #Plotting correlation  \n",
    "\n",
    "    \n",
    "    sns.pairplot(df[['nomination_winner', 'ratingCount','rating', 'runtimeMinutes' ]].head(5000));\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** 異なる特徴を試してみて、各モデルの roc スコアを確認します**。 ** 特徴量選択ボックス**の手順を実行します。\n",
    "\n",
    "<a href='#feature selection'>**特徴量選択ボックスへ移動**</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if feature_premiere_wide:\n",
    "    X_train = df[['rating', 'ratingCount', 'runtimeMinutes','premiere','wide']]\n",
    "elif feature_premiere:\n",
    "    X_train = df[['rating', 'ratingCount', 'runtimeMinutes','premiere' ]]\n",
    "elif feature_wide:\n",
    "    X_train = df[['rating', 'ratingCount',  'runtimeMinutes' ,'wide']]\n",
    "else :\n",
    "    X_train = df[['rating', 'ratingCount',  'runtimeMinutes']]\n",
    "\n",
    "\n",
    "Y_train = df['nomination_winner']\n",
    "\n",
    "if normalize_flag:\n",
    "    X_train=(StandardScaler().fit_transform(X_train ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下で、**主成分分析 (PCA)** を実行して、特徴セットを 3 つの主成分に減らします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "\n",
    "\n",
    "if feature_pca_3D:\n",
    "    pca = decomposition.PCA(n_components=3)\n",
    "    \n",
    "     \n",
    "    principalComponents = pca.fit_transform(X_train )\n",
    "\n",
    "    principalDf = pd.DataFrame(data = principalComponents\n",
    "                 , columns = ['principal component 1', 'principal component 2','principal component 3'])\n",
    "    \n",
    "    \n",
    "    finalDf = pd.concat([principalDf, Y_train], axis = 1)\n",
    "    finalDf = finalDf.head(2000)\n",
    "    targets = [1, 0 ]\n",
    "    colors = ['r', 'g' ]\n",
    "     \n",
    "    my_dpi = 96\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    \n",
    "    ax = fig.add_subplot(111,projection='3d' )\n",
    "    ax.set_xlabel('Principal Component 1', fontsize = 8)\n",
    "    ax.set_ylabel('Principal Component 2', fontsize = 8)\n",
    "    ax.set_zlabel('Principal Component 3', fontsize = 8)\n",
    "    ax.set_title('3 component PCA', fontsize = 15)\n",
    "    for target, color in zip(targets,colors):\n",
    "        indicesToKeep = finalDf['nomination_winner'] == target\n",
    "        \n",
    "        \n",
    "        ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "                    , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "                   ,  finalDf.loc[indicesToKeep, 'principal component 3']\n",
    "                    , c = color,  linewidth=0.5)\n",
    "        \n",
    "    ax.legend(targets)\n",
    "    #ax.grid() \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    \n",
    "    # In order to use PCA_3D for testing, uncomment below line and run this cell.\n",
    "    #X_train = X_train_pca \n",
    "    \n",
    "elif feature_pca_2D:\n",
    "    \n",
    "     \n",
    "    pca = decomposition.PCA(n_components=2)\n",
    "    principalComponents = pca.fit_transform(X_train )\n",
    "\n",
    "    \n",
    "    \n",
    "    principalDf = pd.DataFrame(data = principalComponents\n",
    "                 , columns = ['principal component 1', 'principal component 2'] )\n",
    "    \n",
    "    finalDf = pd.concat([principalDf, Y_train], axis = 1)\n",
    "    finalDf = finalDf.head(50)\n",
    "    \n",
    "    targets = [1, 0 ]\n",
    "    colors = ['r', 'g' ]\n",
    "     \n",
    "    my_dpi = 96\n",
    "  \n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = fig.add_subplot(111 )\n",
    "\n",
    "    ax.set_xlabel('Principal Component 1', fontsize = 8)\n",
    "    ax.set_ylabel('Principal Component 2', fontsize = 8)\n",
    "\n",
    "    ax.set_title('2 component PCA', fontsize = 15)\n",
    "    for target, color in zip(targets,colors):\n",
    "        indicesToKeep = finalDf['nomination_winner'] == target\n",
    "        ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "                   , finalDf.loc[indicesToKeep, 'principal component 2']               \n",
    "                    , c = color,  linewidth=0.5)\n",
    "\n",
    "    ax.legend(targets)\n",
    "    #ax.grid() \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    \n",
    "    # In order to use PCA_2D for testing, uncomment below line and run this cell.\n",
    "    #X_train = X_train_pca \n",
    "    \n",
    "  \n",
    "\n",
    "#PCA ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"ノミネート/受賞\" 3D ポイント (赤いドット) が、非\"ノミネート/受賞\" 3D ポイント (緑のドット) のクラスター内にあることが、分析中に示されます。これは、PCA 分析を使用して 3D モデルのデータを分類するのが難しいことを表しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットをトレーニングデータとテストデータのセットに分割します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.25, random_state=0)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アルゴリズムの比較と選択"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression、Support Vector Machine (SVM)、Random Forest (RF)、Decision Tree (DT)、Gradient Boosting (GB)、Multi-Layer Perceptron (NN) 分類スキームを使用してモデルを構築します。Precision、Recall、ROC、F1、Accuracy などのさまざまなスコアが測定されます。また、異なるモデルの ROC 曲線をプロットします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LR_flag:\n",
    "\n",
    "# Logistic Regression Model\n",
    "\n",
    "    logisticRegr = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                        multi_class='multinomial', max_iter=1000)\n",
    "    logisticRegr.fit(x_train, y_train)\n",
    "    y_test_pred_LR = cross_val_predict(logisticRegr, x_test, y_test, cv=3)\n",
    "    score = logisticRegr.score(x_test, y_test)\n",
    "    y_test_pred = y_test_pred_LR\n",
    "    print(\"LR Accuracy\",accuracy_score(y_test, y_test_pred))\n",
    "    roc = roc_auc_score(y_test, y_test_pred)\n",
    "    print(\"roc score\", roc)\n",
    "    print(\"Classification Report\")\n",
    "    print(\"=\"*50)\n",
    "    LR_CR = classification_report(y_test, y_test_pred)\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    # Plot   confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['Class 0', 'Class 1'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "    \n",
    "    # Compute ROC curve and ROC area\n",
    "    #fpr, tpr, thrsehold = roc_curve(y_test , y_test_pred)\n",
    "  \n",
    "\n",
    "    \n",
    "    logit_roc_auc = roc_auc_score(y_test_pred, logisticRegr.predict(x_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, logisticRegr.predict_proba(x_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='Logistic Regression ' )\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "     \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if SVM_flag:\n",
    "    # SVM Model\n",
    "\n",
    "    sgd_clf = SGDClassifier(random_state=0, loss=\"log\", max_iter=1000, tol=3 )\n",
    "    sgd_clf.fit(x_train, y_train)\n",
    "    cross_val_score(sgd_clf, x_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "    y_test_pred_SVC = cross_val_predict(sgd_clf, x_test, y_test, cv=3)\n",
    "    predictions = sgd_clf.predict(x_test)\n",
    "    score = sgd_clf.score(x_test, y_test)\n",
    "    y_test_pred = y_test_pred_SVC\n",
    "    print(\"SVM Accuracy\",accuracy_score(y_test, y_test_pred))\n",
    "    roc = roc_auc_score(y_test, y_test_pred_SVC)\n",
    "    print(\"roc score\", roc)\n",
    "    SVM_CR = classification_report(y_test, y_test_pred)\n",
    "    print(\"Classification Report\")\n",
    "    print(\"=\"*50)\n",
    "    print(SVM_CR)\n",
    "    # Plot   confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['Class 0', 'Class 1'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr, tpr, thrsehold = roc_curve(y_test , y_test_pred)\n",
    "     \n",
    "  \n",
    "    \n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test_pred, sgd_clf.predict(x_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, sgd_clf.predict_proba(x_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='SVM  ' )\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "     \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if DT_flag:\n",
    "    # Decision Tree Model\n",
    "\n",
    "    DT = DecisionTreeClassifier(random_state=42)\n",
    "    DT.fit(x_train, y_train)\n",
    "    cross_val_score(DT, x_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "    y_test_pred_DT = cross_val_predict(DT, x_test, y_test, cv=3)\n",
    "    predictions = DT.predict(x_test)\n",
    "    score = DT.score(x_test, y_test)\n",
    "    y_test_pred = y_test_pred_DT\n",
    "    print(\"DT Accuracy\",accuracy_score(y_test, y_test_pred))\n",
    "    roc = roc_auc_score(y_test, y_test_pred)\n",
    "    print(\"roc score\", roc)\n",
    "    DT_CR = classification_report(y_test, y_test_pred)\n",
    "    print(\"Classification Report\")\n",
    "    print(\"=\"*50)\n",
    "    print(DT_CR)\n",
    "    # Plot   confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['Class 0', 'Class 1'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr, tpr, thrsehold = roc_curve(y_test , y_test_pred)\n",
    " \n",
    "    \n",
    " \n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test_pred, DT.predict(x_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, DT.predict_proba(x_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='Decision Tree '  )\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "     \n",
    "    plt.show()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "if RF_flag:\n",
    "    # Ensemble Random Forest Model\n",
    "\n",
    "    RF = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "    RF.fit(x_train, y_train)\n",
    "    cross_val_score(RF, x_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "    y_test_pred_RF = cross_val_predict(RF, x_test, y_test, cv=3)\n",
    "    predictions = RF.predict(x_test)\n",
    "    score = RF.score(x_test, y_test)\n",
    "    y_test_pred = y_test_pred_RF\n",
    "    print(\"RF Accuracy\",accuracy_score(y_test, y_test_pred))\n",
    "    roc = roc_auc_score(y_test, y_test_pred)\n",
    "    print(\"roc score\", roc)\n",
    "    RF_CR = classification_report(y_test, y_test_pred)\n",
    "    print(\"Classification Report\")\n",
    "    print(\"=\"*50)\n",
    "    print(RF_CR)\n",
    "    # Plot   confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['Class 0', 'Class 1'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "    \n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr, tpr, thrsehold = roc_curve(y_test , y_test_pred)\n",
    " \n",
    "    roc_auc = roc_auc_score(y_test_pred, sgd_clf.predict(x_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, sgd_clf.predict_proba(x_test)[:,1])\n",
    " \n",
    "    \n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test_pred, RF.predict(x_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, RF.predict_proba(x_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='Random Forest ' )\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "     \n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if GB_flag:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=0.5, max_features=2, max_depth=2, random_state=0)\n",
    "    gb_clf.fit(x_train, y_train)\n",
    "\n",
    "    cross_val_score(gb_clf, x_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "    y_test_pred_gb = cross_val_predict(gb_clf, x_test, y_test, cv=3)\n",
    "    predictions = gb_clf.predict(x_test)\n",
    "    score = gb_clf.score(x_test, y_test)\n",
    "    y_test_pred = y_test_pred_gb\n",
    "    print(\"GB Accuracy\",accuracy_score(y_test, y_test_pred))\n",
    "    roc = roc_auc_score(y_test, y_test_pred)\n",
    "    print(\"roc score\", roc)\n",
    "    GB_CR = classification_report(y_test, y_test_pred)\n",
    "    print(\"Classification Report\")\n",
    "    print(\"=\"*50)\n",
    "    print(GB_CR)\n",
    "    \n",
    "    # Plot   confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['Class 0', 'Class 1'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "    \n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr, tpr, thrsehold = roc_curve(y_test , y_test_pred)\n",
    "    roc_auc  = auc(fpr , tpr )\n",
    " \n",
    " \n",
    "    roc_auc = roc_auc_score(y_test_pred, gb_clf.predict(x_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, gb_clf.predict_proba(x_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='Gradient Boosting  '  )\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "     \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NN_flag:\n",
    "\n",
    "\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(20, 20, 20), max_iter=1000)\n",
    "    mlp.fit(x_test, y_test)\n",
    "\n",
    "    cross_val_score(mlp, x_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "\n",
    "    y_test_pred_NN = cross_val_predict(mlp, x_test, y_test, cv=3)\n",
    "    predictions = mlp.predict(x_test)\n",
    "    score = mlp.score(x_test, y_test)\n",
    "\n",
    "    y_test_pred = y_test_pred_NN\n",
    "    print(\"NN Accuracy\",accuracy_score(y_test, y_test_pred))\n",
    "    roc = roc_auc_score(y_test, y_test_pred)\n",
    "    print(\"roc score\", roc)\n",
    "    NN_CR = classification_report(y_test, y_test_pred)\n",
    "    print(\"Classification Report\")\n",
    "    print(\"=\"*50)\n",
    "    print(NN_CR)\n",
    "    \n",
    "    # Plot   confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['Class 0', 'Class 1'],\n",
    "                          title='Confusion matrix, without normalization')\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr, tpr, thrsehold = roc_curve(y_test , y_test_pred)\n",
    "    roc_auc  = auc(fpr , tpr )\n",
    "  \n",
    " \n",
    "    \n",
    "     \n",
    "    roc_auc = roc_auc_score(y_test_pred, mlp.predict(x_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, mlp.predict_proba(x_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='MLP  '  )\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('Log_ROC')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below will display classification report of respective models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_list = [LR_CR,SVM_CR,DT_CR,RF_CR,GB_CR,NN_CR]\n",
    "model_list = ['LR','SVM','DT','RF','GB','NN']\n",
    "def display_report(model,report):\n",
    "    display(Markdown(model+\" **Model Classification Report** \\n\"))\n",
    "    print('\\n',report)\n",
    "    \n",
    "for (model,report) in zip(model_list, report_list):\n",
    "    display_report(model,report)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 質問\n",
    "**精度、検出率、F1 メトリクス **に基づいて、どの**モデル**が予測に最も適していると思いますか?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ここで、特定のモデルに対して 2005 のデータを実行してください。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルのテスト"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のコードを実行して**2005 データ**を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2005.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特徴量選択ボックスで選択した特徴に基づく X_train および Y_train データを選択します。以下のリンクをクリックして、選択を確認できます。\n",
    "\n",
    "<a href='#feature selection'>**特徴量選択ボックスに移動**</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature_premiere_wide:\n",
    "    X_train = df_2005[['rating', 'ratingCount', 'runtimeMinutes','premiere','wide']]\n",
    "elif feature_premiere:\n",
    "    X_train = df_2005[['rating', 'ratingCount', 'runtimeMinutes','premiere' ]]\n",
    "elif feature_wide:\n",
    "    X_train = df_2005[['rating', 'ratingCount',  'runtimeMinutes' ,'wide']]\n",
    "else :\n",
    "    X_train = df_2005[['rating', 'ratingCount',  'runtimeMinutes']]\n",
    "\n",
    "\n",
    "Y_train = df_2005['nomination_winner']\n",
    "\n",
    "if normalize_flag:\n",
    "    X_train=(StandardScaler().fit_transform(X_train ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットをトレーニングデータセットとテストデータセットに分割します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**選択したモデルを実行します**。前の手順で最適なモデルボックスからコードをコピーし、以下のボックスに貼り付けます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_chainer_p27",
   "language": "python",
   "name": "conda_chainer_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
